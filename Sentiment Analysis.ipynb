{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "from nltk.tokenize import sent_tokenize, RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cik_list = pd.read_csv('cik_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching data\n",
    "def extract_data(link):\n",
    "    link = 'https://www.sec.gov/Archives/' + link.strip()\n",
    "    headers = {\"user-agent\": \"Mozilla/5.0\"}\n",
    "    f = requests.get(link,headers=headers)\n",
    "    text = f.text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = cik_list['SECFNAME'].apply(extract_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning data\n",
    "def clean_data(text):\n",
    "    #Remove HTML Tags\n",
    "    text = re.sub('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});','', text)\n",
    "    \n",
    "    #remove extra line and tabs\n",
    "    text = text.replace('\\n',' ')\n",
    "    text = text.replace('\\t',' ')\n",
    "\n",
    "    #remove punctuation \n",
    "#     text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # remove numbers and special characters\n",
    "    text = re.sub(r'[^a-zA-z.,!?/:;\\\"\\'\\s]',' ',text)\n",
    "    \n",
    "    #remove multiple spaces\n",
    "    text = re.sub('(?s) +',' ',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_data = {'raw_text':report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df = pd.DataFrame(report_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['clean_data'] = report_df['raw_text'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"StopWords_Generic.txt\", \"r\")\n",
    "stop_words = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordList = stop_words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+') #removing punctuation\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    filtered_words = list(filter(lambda token: token not in stopWordList, tokens)) # filtering stopwords\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['filtered'] = report_df['clean_data'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = pd.read_csv('Positive-Table.csv')\n",
    "negative_df = pd.read_csv('Negative-Table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveWords = positive_df['Unnamed: 0'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveWordsList = positiveWords.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativeWords = negative_df['Unnamed: 0'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativeWordsList = negativeWords.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveWordsList = list(filter(lambda word: word not in stopWordList, positiveWordsList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativeWordsList = list(filter(lambda word: word not in stopWordList, negativeWordsList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating positive score \n",
    "def positive_score(token):\n",
    "    posWords = 0\n",
    "    for word in token:\n",
    "        if word in positiveWordsList:\n",
    "            posWords  += 1\n",
    "    return posWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Negative score\n",
    "def negative_score(token):\n",
    "    negWords=0\n",
    "    for word in token:\n",
    "        if word in negativeWordsList:\n",
    "            negWords -=1\n",
    "    return negWords*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating polarity score\n",
    "def polarity_score(positiveScore, negativeScore):\n",
    "    pol_score = (positiveScore - negativeScore) / ((positiveScore + negativeScore) + 0.000001)\n",
    "    return pol_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['positive_score'] = report_df['filtered'].apply(positive_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['negative_score'] = report_df['filtered'].apply(negative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['polarity_score'] = report_df.apply(lambda x: polarity_score(x.positive_score,x.negative_score),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg_sentence_length\n",
    "def average_sentence_length(text,word_token):\n",
    "    sentence_token = sent_tokenize(text)\n",
    "    totalWordCount = len(word_token)\n",
    "    totalSentences = len(sentence_token)\n",
    "    average_sent_length = 0\n",
    "    if totalSentences != 0:\n",
    "        average_sent_length = totalWordCount / totalSentences    \n",
    "    return round(average_sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['average_sentence_length'] = report_df.apply(lambda x: average_sentence_length(x.clean_data,x.filtered),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#syllable count\n",
    "def syllable_count(word):\n",
    "    vowels = 0\n",
    "    word = word.lower()\n",
    "    if word.endswith(('es','ed')):\n",
    "            pass\n",
    "    else:\n",
    "        for w in word:\n",
    "            if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
    "                vowels += 1\n",
    "    return vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complex words\n",
    "def complex_word_count(token):\n",
    "    complexWords = 0\n",
    "    for word in token:\n",
    "        if syllable_count(word) > 2:\n",
    "            complexWords+=1\n",
    "    return complexWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating complex word percentage\n",
    "def complex_word_percentage(token):\n",
    "    totalWords = len(token)\n",
    "    complexWords = complex_word_count(token)\n",
    "    return complexWords/totalWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['percentage_of_complex_words'] = report_df['filtered'].apply(complex_word_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fog index\n",
    "def fog_index(avg_sentence_length,percentage_complex):\n",
    "    return 0.4*(avg_sentence_length+percentage_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['fog_index'] = report_df.apply(lambda x:fog_index(x.average_sentence_length,x.percentage_of_complex_words),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['word_count'] = report_df['filtered'].apply(lambda x:len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['complex_word_count'] = report_df['filtered'].apply(complex_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainty_df = pd.read_csv('uncertainty_dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncertainWords = uncertainty_df['Word'].apply(lambda x:x.lower())\n",
    "uncertainWordsList = uncertainWords.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating uncertainity score \n",
    "def uncertainty_score(token):\n",
    "    uncWords = 0\n",
    "    for word in token:\n",
    "        if word in uncertainWordsList:\n",
    "            uncWords  += 1\n",
    "    return uncWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraining_df = pd.read_csv('constraining_dictionary.csv')\n",
    "constrainWords = constraining_df['Word'].apply(lambda x:x.lower())\n",
    "constrainWordsList = constrainWords.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating constraining score \n",
    "def constraining_score(token):\n",
    "    constrainWords = 0\n",
    "    for word in token:\n",
    "        if word in constrainWordsList:\n",
    "            constrainWords  += 1\n",
    "    return constrainWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['uncertainty_score'] = report_df['filtered'].apply(uncertainty_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['constraining_score'] = report_df['filtered'].apply(constraining_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive word proportion\n",
    "def positive_word_proportion(positiveScore,wordcount):\n",
    "    pwp = 0\n",
    "    if wordcount !=0:\n",
    "        pwp = positiveScore / wordcount\n",
    "    return pwp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative word proportion\n",
    "def negative_word_proportion(negativeScore,wordcount):\n",
    "    nwp = 0\n",
    "    if wordcount !=0:\n",
    "        nwp = negativeScore / wordcount\n",
    "    return nwp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['positive_word_proportion'] = report_df.apply(lambda x:positive_word_proportion(x.positive_score,x.word_count),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['negative_word_proportion'] = report_df.apply(lambda x:negative_word_proportion(x.negative_score,x.word_count),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncertain word proportion\n",
    "def uncertain_word_proportion(uncertainScore,wordcount):\n",
    "    uwp = 0\n",
    "    if wordcount !=0:\n",
    "        uwp = uncertainScore / wordcount\n",
    "    return uwp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraining word proportion\n",
    "def constrain_word_proportion(constrainScore,wordcount):\n",
    "    cwp = 0\n",
    "    if wordcount !=0:\n",
    "        cwp = constrainScore / wordcount\n",
    "    return cwp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['uncertainty_word_proportion'] = report_df.apply(lambda x:uncertain_word_proportion(x.uncertainty_score,x.word_count),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['constraining_word_proportion'] = report_df.apply(lambda x:constrain_word_proportion(x.constraining_score,x.word_count),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df['constraining_words_whole_report'] = report_df['filtered'].apply(constraining_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report = cik_list.join(report_df.iloc[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report.to_csv('final_report.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
